{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "276a6144",
   "metadata": {},
   "source": [
    "# AI Evaluation with Azure AI Foundry\n",
    "\n",
    "This notebook demonstrates how to use Azure AI Evaluation tools to assess the quality and safety of AI responses. We'll explore three types of evaluators:\n",
    "\n",
    "1. **NLP-based evaluators** (e.g., BLEU score) for measuring text similarity\n",
    "2. **AI-assisted quality evaluators** (e.g., Relevance) that use language models to assess quality\n",
    "3. **AI-assisted safety evaluators** (e.g., Violence detection) for content safety\n",
    "\n",
    "Let's start by importing the necessary libraries and evaluators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ad36ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from azure.ai.evaluation import evaluate, RelevanceEvaluator, ViolenceEvaluator, BleuScoreEvaluator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9440e3a9",
   "metadata": {},
   "source": [
    "## 1. NLP-based Evaluation: BLEU Score\n",
    "\n",
    "The BLEU (Bilingual Evaluation Understudy) score is a traditional NLP metric that measures how similar a generated response is to a reference text. It's based on n-gram matching and doesn't require a language model.\n",
    "\n",
    "**Use case**: Measuring text similarity, especially useful for translation tasks or when you have ground truth reference answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d05f3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NLP bleu score evaluator\n",
    "bleu_score_evaluator = BleuScoreEvaluator()\n",
    "result = bleu_score_evaluator(\n",
    "    response=\"Tokyo is the capital of Japan.\",\n",
    "    ground_truth=\"The capital of Japan is Tokyo.\"\n",
    ")\n",
    "\n",
    "print(f\"BLEU Score Result: {result}\")\n",
    "print(f\"Score: {result['bleu_score']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d28a110",
   "metadata": {},
   "source": [
    "## 2. AI-Assisted Quality Evaluation: Relevance\n",
    "\n",
    "AI-assisted evaluators use language models to assess the quality of responses. The Relevance evaluator determines how well the response answers the given query.\n",
    "\n",
    "**Requirements**: \n",
    "- Azure OpenAI endpoint and API key\n",
    "- Deployment name for your model\n",
    "\n",
    "First, let's set up the model configuration using environment variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c0e949",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AI assisted quality evaluator\n",
    "model_config = {\n",
    "    \"azure_endpoint\": os.environ.get(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "    \"api_key\": os.environ.get(\"AZURE_OPENAI_API_KEY\"),\n",
    "    \"azure_deployment\": os.environ.get(\"AZURE_OPENAI_DEPLOYMENT\"),\n",
    "}\n",
    "\n",
    "print(\"Model Configuration:\")\n",
    "print(f\"Endpoint: {model_config['azure_endpoint']}\")\n",
    "print(f\"Deployment: {model_config['azure_deployment']}\")\n",
    "print(f\"API Key configured: {'Yes' if model_config['api_key'] else 'No'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a994bc",
   "metadata": {},
   "source": [
    "Now let's create the Relevance evaluator and test it with a simple query-response pair:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52fa5216",
   "metadata": {},
   "outputs": [],
   "source": [
    "relevance_evaluator = RelevanceEvaluator(model_config)\n",
    "result = relevance_evaluator(\n",
    "    query=\"What is the capital of Japan?\",\n",
    "    response=\"The capital of Japan is Tokyo.\"\n",
    ")\n",
    "\n",
    "print(f\"Relevance Evaluation Result: {result}\")\n",
    "print(f\"Relevance Score: {result['relevance']}\")\n",
    "print(f\"Reasoning: {result.get('gpt_relevance', 'Not provided')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c0f92e8",
   "metadata": {},
   "source": [
    "## 3. AI-Assisted Safety Evaluation: Violence Detection\n",
    "\n",
    "Safety evaluators help detect potentially harmful content in AI responses. The Violence evaluator checks for violent content in the response.\n",
    "\n",
    "**Configuration Options**: There are two ways to configure the Azure AI Project for safety evaluators:\n",
    "1. Using project details (subscription ID, resource group, project name)\n",
    "2. Using the project URL directly\n",
    "\n",
    "Let's explore both approaches."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d41689ba",
   "metadata": {},
   "source": [
    "### Option 1: Using Azure AI Project Details\n",
    "\n",
    "This approach requires you to specify the subscription ID, resource group name, and project name separately:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f52ce5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option #1 : Using Azure AI Project Details from environment variables\n",
    "azure_ai_project = {\n",
    "    \"subscription_id\": os.environ.get(\"AZURE_SUBSCRIPTION_ID\"),\n",
    "    \"resource_group_name\": os.environ.get(\"AZURE_RESOURCE_GROUP\"),\n",
    "    \"project_name\": os.environ.get(\"AZURE_AI_PROJECT_NAME\"),\n",
    "}\n",
    "if not all(azure_ai_project.values()):\n",
    "    print(\"One or more Azure AI Project details are missing from environment variables.\")\n",
    "else:\n",
    "    print(\"All Azure AI Project details are set:\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3388d459",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Azure AI Project configuration:\")\n",
    "for key, value in azure_ai_project.items():\n",
    "    print(f\"  {key}: {value if value else 'NOT SET'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ffe9969",
   "metadata": {},
   "outputs": [],
   "source": [
    "violence_evaluator = ViolenceEvaluator(azure_ai_project)\n",
    "result = violence_evaluator(\n",
    "    query=\"What is the capital of France?\",\n",
    "    response=\"Paris.\"\n",
    ")\n",
    "\n",
    "print(f\"Violence Evaluation Result (Option 1): {result}\")\n",
    "print(f\"Violence Score: {result.get('violence', 'Not provided')}\")\n",
    "print(f\"Violence Reason: {result.get('violence_reason', 'Not provided')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a77b2289",
   "metadata": {},
   "source": [
    "### Option 2: Using Azure AI Project URL\n",
    "\n",
    "This approach uses a direct URL to your Azure AI project, which is more concise:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850e0298",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option # 2 : Using Azure AI Project URL \n",
    "azure_ai_project = \"https://{resource_name}.services.ai.azure.com/api/projects/{project_name}\"\n",
    "\n",
    "# Note: Replace {resource_name} and {project_name} with your actual values\n",
    "print(f\"Azure AI Project URL (Option 2): {azure_ai_project}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed736a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "violence_evaluator = ViolenceEvaluator(azure_ai_project)\n",
    "result = violence_evaluator(\n",
    "    query=\"What is the capital of France?\",\n",
    "    response=\"Paris.\"\n",
    ")\n",
    "\n",
    "print(f\"Violence Evaluation Result (Option 2): {result}\")\n",
    "print(f\"Violence Score: {result.get('violence', 'Not provided')}\")\n",
    "print(f\"Violence Reason: {result.get('violence_reason', 'Not provided')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee2ca984",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated three types of evaluation approaches in Azure AI Foundry:\n",
    "\n",
    "1. **NLP-based Evaluators (BLEU Score)**: Fast, deterministic metrics that don't require API calls. Good for measuring text similarity against ground truth.\n",
    "\n",
    "2. **AI-assisted Quality Evaluators (Relevance)**: Use language models to assess quality aspects like relevance, coherence, fluency, etc. More nuanced but require API calls.\n",
    "\n",
    "3. **AI-assisted Safety Evaluators (Violence)**: Specifically designed to detect harmful content. Essential for production AI systems.\n",
    "\n",
    "### Key Takeaways:\n",
    "- Choose evaluators based on your specific use case and requirements\n",
    "- NLP metrics are fast but limited in scope\n",
    "- AI-assisted evaluators provide more nuanced assessment but require Azure OpenAI or AI Foundry resources\n",
    "- Safety evaluators are crucial for responsible AI deployment\n",
    "- You can configure Azure AI projects using either detailed parameters or direct URLs\n",
    "\n",
    "### Next Steps:\n",
    "- Configure your actual Azure credentials and project details\n",
    "- Experiment with different evaluator types and parameters\n",
    "- Consider combining multiple evaluators for comprehensive assessment\n",
    "- Integrate evaluations into your AI development workflow"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
