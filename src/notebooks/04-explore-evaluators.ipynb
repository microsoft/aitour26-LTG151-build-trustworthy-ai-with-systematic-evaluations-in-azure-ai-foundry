{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c33f919e",
   "metadata": {},
   "source": [
    "# Explore Agent Evaluators\n",
    "\n",
    "Welcome! This notebook introduces you to evaluating AI agents using specialized evaluators from the Azure AI Evaluation SDK.\n",
    "\n",
    "## What You'll Learn\n",
    "- How to use specialized agent evaluators (Intent Resolution, Tool Call Accuracy, Task Adherence)\n",
    "- How to create and evaluate agent scenarios with tool interactions\n",
    "- How to assess complex multi-step agent conversations\n",
    "- How to run batch evaluations for multiple agent interactions\n",
    "- Best practices for evaluating production AI agents\n",
    "\n",
    "Let's get started! üöÄ\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3efa1b33",
   "metadata": {},
   "source": [
    "## Understanding Agent Evaluation\n",
    "\n",
    "AI agents are powerful productivity assistants that can create complex workflows for business needs. Unlike simple query-response AI systems, agents involve multiple steps:\n",
    "\n",
    "- **Intent Recognition** - Understanding what the user wants to accomplish\n",
    "- **Tool Selection & Usage** - Choosing and correctly using available tools\n",
    "- **Task Execution** - Following through on the assigned workflow\n",
    "- **Response Generation** - Providing helpful and accurate responses\n",
    "\n",
    "When a user queries \"What's the weather tomorrow?\", an agentic workflow might involve reasoning through user intents, calling weather APIs, and utilizing retrieval-augmented generation. It's crucial to evaluate each step of the workflow, plus the quality and safety of the final output.\n",
    "\n",
    "Azure AI Foundry provides specialized **agent evaluators** that assess these unique aspects:\n",
    "\n",
    "1. **Intent Resolution** - Measures whether the agent correctly identifies the user's intent\n",
    "2. **Tool Call Accuracy** - Measures whether the agent made the correct function tool calls\n",
    "3. **Task Adherence** - Measures whether the agent's response adheres to its assigned tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be0bb312",
   "metadata": {},
   "source": [
    "## Step 1: Verify Azure AI Evaluation SDK\n",
    "\n",
    "Let's ensure the Azure AI Evaluation SDK is installed. It provides specialized evaluators for agentic workflows:\n",
    "- **IntentResolutionEvaluator** - For measuring intent understanding\n",
    "- **ToolCallAccuracyEvaluator** - For assessing tool usage correctness\n",
    "- **TaskAdherenceEvaluator** - For evaluating task completion fidelity\n",
    "\n",
    "These work alongside standard quality and safety evaluators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d68ceeaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip list | grep azure-ai-evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "917dcca8",
   "metadata": {},
   "source": [
    "## Step 2: Import Required Libraries\n",
    "\n",
    "Let's import the specialized agent evaluators and supporting libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c42286",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import agent-specific evaluators\n",
    "from azure.ai.evaluation import (\n",
    "    IntentResolutionEvaluator, \n",
    "    ToolCallAccuracyEvaluator, \n",
    "    TaskAdherenceEvaluator\n",
    ")\n",
    "\n",
    "# Import standard quality evaluators\n",
    "from azure.ai.evaluation import (\n",
    "    RelevanceEvaluator, \n",
    "    CoherenceEvaluator, \n",
    "    FluencyEvaluator\n",
    ")\n",
    "\n",
    "# Import supporting libraries\n",
    "from azure.identity import DefaultAzureCredential\n",
    "import os\n",
    "import json\n",
    "\n",
    "print(\"‚úÖ Successfully imported evaluation modules!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a125545",
   "metadata": {},
   "source": [
    "## Step 3: Configure Azure AI Project\n",
    "\n",
    "Let's set up our connection to Azure AI Foundry using environment variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2534e351",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Azure AI project configuration from environment variables\n",
    "azure_ai_foundry_name = os.environ.get(\"AZURE_AI_FOUNDRY_NAME\")\n",
    "project_name = os.environ.get(\"AZURE_AI_PROJECT_NAME\")\n",
    "\n",
    "if not azure_ai_foundry_name or not project_name:\n",
    "    raise ValueError(\"AZURE_AI_FOUNDRY_NAME or AZURE_AI_PROJECT_NAME environment variable is not set\")\n",
    "\n",
    "# Construct the Azure AI Foundry project URL\n",
    "azure_ai_project_url = f\"https://{azure_ai_foundry_name}.services.ai.azure.com/api/projects/{project_name}\"\n",
    "\n",
    "# Set up model configuration for evaluators\n",
    "model_config = {\n",
    "    \"azure_endpoint\": os.environ.get(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "    \"api_key\": os.environ.get(\"AZURE_OPENAI_API_KEY\"),\n",
    "    \"azure_deployment\": os.environ.get(\"AZURE_OPENAI_DEPLOYMENT\"),\n",
    "}\n",
    "\n",
    "print(f\"‚úÖ Azure AI project configured: {project_name}\")\n",
    "print(f\"‚úÖ Model deployment: {model_config['azure_deployment']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b63e08a6",
   "metadata": {},
   "source": [
    "## Step 4: Initialize Evaluators\n",
    "\n",
    "Before we start evaluating, let's initialize the agent evaluators. We'll use:\n",
    "- **IntentResolutionEvaluator** - Returns Likert score (1-5) for intent understanding\n",
    "- **TaskAdherenceEvaluator** - Ensures agents stay within defined scope\n",
    "- **ToolCallAccuracyEvaluator** - Assesses correct tool selection and usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "700357c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Azure credential\n",
    "credential = DefaultAzureCredential()\n",
    "print(\"‚úÖ Azure credential created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14899cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize agent evaluators\n",
    "intent_evaluator = IntentResolutionEvaluator(model_config=model_config)\n",
    "task_adherence_evaluator = TaskAdherenceEvaluator(model_config=model_config)\n",
    "\n",
    "print(\"‚úÖ Agent evaluators initialized successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e827f322",
   "metadata": {},
   "source": [
    "## Step 5: Intent Resolution Evaluation\n",
    "\n",
    "**Intent Resolution** measures whether an agent correctly identifies and responds to the user's intent. This is fundamental to agent performance.\n",
    "\n",
    "Let's test with good and poor examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ec2db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 1: Good Intent Resolution\n",
    "print(\"üìä Test 1: Good Intent Resolution\\n\")\n",
    "\n",
    "query_good = \"What are the opening hours of the Eiffel Tower?\"\n",
    "response_good = \"The Eiffel Tower is open daily from 9:00 AM to 11:00 PM. During summer months (mid-June to early September), it stays open until midnight.\"\n",
    "\n",
    "result_good = intent_evaluator(\n",
    "    query=query_good,\n",
    "    response=response_good\n",
    ")\n",
    "\n",
    "print(f\"Query: {query_good}\")\n",
    "print(f\"Response: {response_good}\")\n",
    "print(f\"\\n‚úÖ Intent Resolution Score: {result_good.get('intent_resolution', 'N/A')}\")\n",
    "print(f\"‚úÖ Result: {result_good.get('intent_resolution_result', 'N/A')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e1830a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 2: Poor Intent Resolution\n",
    "print(\"üìä Test 2: Poor Intent Resolution\\n\")\n",
    "\n",
    "query_poor = \"What are the opening hours of the Eiffel Tower?\"\n",
    "response_poor = \"Paris is a beautiful city with many historical landmarks and museums.\"\n",
    "\n",
    "result_poor = intent_evaluator(\n",
    "    query=query_poor,\n",
    "    response=response_poor\n",
    ")\n",
    "\n",
    "print(f\"Query: {query_poor}\")\n",
    "print(f\"Response: {response_poor}\")\n",
    "print(f\"\\n‚ùå Intent Resolution Score: {result_poor.get('intent_resolution', 'N/A')}\")\n",
    "print(f\"‚ùå Result: {result_poor.get('intent_resolution_result', 'N/A')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4afd4bb",
   "metadata": {},
   "source": [
    "## Step 6: Tool Call Accuracy Evaluation\n",
    "\n",
    "**Tool Call Accuracy** measures whether an agent makes the correct function tool calls for a user's request. This is crucial for agents that interact with external systems.\n",
    "\n",
    "First, let's define the tools available to our agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4b18ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define available tools for our agent\n",
    "tool_definitions = [\n",
    "    {\n",
    "        \"name\": \"get_weather\",\n",
    "        \"description\": \"Fetches current weather information for a specified location.\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"location\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The location to get weather for (city, state/country).\"\n",
    "                },\n",
    "                \"units\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"Temperature units (celsius or fahrenheit).\",\n",
    "                    \"enum\": [\"celsius\", \"fahrenheit\"]\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"location\"]\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"get_stock_price\",\n",
    "        \"description\": \"Gets the current stock price for a company symbol.\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"symbol\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"Stock symbol (e.g., MSFT, AAPL).\"\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"symbol\"]\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "print(\"‚úÖ Defined tools for our agent:\")\n",
    "for tool in tool_definitions:\n",
    "    print(f\"   - {tool['name']}: {tool['description']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59381273",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Tool Call Accuracy Evaluator\n",
    "tool_call_evaluator = ToolCallAccuracyEvaluator(model_config=model_config)\n",
    "print(\"‚úÖ Tool Call Accuracy evaluator initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092efd4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 3: Correct Tool Usage\n",
    "print(\"üìä Test 3: Correct Tool Usage\\n\")\n",
    "\n",
    "query_weather = \"What's the weather like in Seattle?\"\n",
    "\n",
    "correct_tool_calls = [\n",
    "    {\n",
    "        \"type\": \"tool_call\",\n",
    "        \"tool_call_id\": \"call_001\",\n",
    "        \"name\": \"get_weather\",\n",
    "        \"arguments\": {\n",
    "            \"location\": \"Seattle\",\n",
    "            \"units\": \"fahrenheit\"\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "result_correct_tool = tool_call_evaluator(\n",
    "    query=query_weather,\n",
    "    tool_calls=correct_tool_calls,\n",
    "    tool_definitions=tool_definitions\n",
    ")\n",
    "\n",
    "print(f\"Query: {query_weather}\")\n",
    "print(f\"Tool Called: {correct_tool_calls[0]['name']}\")\n",
    "print(f\"\\n‚úÖ Tool Call Accuracy Score: {result_correct_tool.get('tool_call_accuracy', 'N/A')}\")\n",
    "print(f\"‚úÖ Result: {result_correct_tool.get('tool_call_accuracy_result', 'N/A')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f8ca52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 4: Incorrect Tool Usage  \n",
    "print(\"üìä Test 4: Incorrect Tool Usage\\n\")\n",
    "\n",
    "query_weather2 = \"What's the weather like in New York?\"\n",
    "\n",
    "# Incorrect: using stock price tool for weather query\n",
    "incorrect_tool_calls = [\n",
    "    {\n",
    "        \"type\": \"tool_call\",\n",
    "        \"tool_call_id\": \"call_002\", \n",
    "        \"name\": \"get_stock_price\",\n",
    "        \"arguments\": {\n",
    "            \"symbol\": \"NYC\"\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "result_incorrect_tool = tool_call_evaluator(\n",
    "    query=query_weather2,\n",
    "    tool_calls=incorrect_tool_calls,\n",
    "    tool_definitions=tool_definitions\n",
    ")\n",
    "\n",
    "print(f\"Query: {query_weather2}\")\n",
    "print(f\"Tool Called: {incorrect_tool_calls[0]['name']} (WRONG!)\")\n",
    "print(f\"\\n‚ùå Tool Call Accuracy Score: {result_incorrect_tool.get('tool_call_accuracy', 'N/A')}\")\n",
    "print(f\"‚ùå Result: {result_incorrect_tool.get('tool_call_accuracy_result', 'N/A')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "039e1377",
   "metadata": {},
   "source": [
    "## Step 7: Task Adherence Evaluation\n",
    "\n",
    "**Task Adherence** measures whether an agent's response adheres to its assigned tasks and system instructions. This ensures agents stay within their defined scope and capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf36f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 5: Good Task Adherence\n",
    "print(\"üìä Test 5: Good Task Adherence\\n\")\n",
    "\n",
    "# Define a customer service agent with specific instructions\n",
    "system_message = \"You are a helpful customer service agent for TechCorp. You can only help with product information, order status, and technical support. You cannot process returns or refunds - direct customers to the returns department for that.\"\n",
    "\n",
    "customer_query = \"Can you tell me about the TechCorp laptop specifications?\"\n",
    "agent_response = \"I'd be happy to help with our laptop specifications! The TechCorp Pro laptop features an Intel i7 processor, 16GB RAM, 512GB SSD, and a 15.6-inch display. It's designed for professional use with excellent battery life. Would you like more details about any specific aspect?\"\n",
    "\n",
    "# Format as conversation messages\n",
    "task_query = [\n",
    "    {\"role\": \"system\", \"content\": system_message},\n",
    "    {\"role\": \"user\", \"content\": customer_query}\n",
    "]\n",
    "\n",
    "task_response = [\n",
    "    {\"role\": \"assistant\", \"content\": agent_response}\n",
    "]\n",
    "\n",
    "result_good_adherence = task_adherence_evaluator(\n",
    "    query=task_query,\n",
    "    response=task_response\n",
    ")\n",
    "\n",
    "print(f\"Customer Query: {customer_query}\")\n",
    "print(f\"Agent Response: {agent_response[:80]}...\")\n",
    "print(f\"\\n‚úÖ Task Adherence Score: {result_good_adherence.get('task_adherence', 'N/A')}\")\n",
    "print(f\"‚úÖ Result: {result_good_adherence.get('task_adherence_result', 'N/A')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd31edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 6: Poor Task Adherence\n",
    "print(\"üìä Test 6: Poor Task Adherence\\n\")\n",
    "\n",
    "customer_query_bad = \"I want to return my laptop for a full refund.\"\n",
    "agent_response_bad = \"Absolutely! I can process that refund for you right now. Just provide your order number and I'll get $1,299 refunded to your account immediately.\"\n",
    "\n",
    "# Same system message - agent should NOT process refunds\n",
    "task_query_bad = [\n",
    "    {\"role\": \"system\", \"content\": system_message},\n",
    "    {\"role\": \"user\", \"content\": customer_query_bad}\n",
    "]\n",
    "\n",
    "task_response_bad = [\n",
    "    {\"role\": \"assistant\", \"content\": agent_response_bad}\n",
    "]\n",
    "\n",
    "result_poor_adherence = task_adherence_evaluator(\n",
    "    query=task_query_bad,\n",
    "    response=task_response_bad\n",
    ")\n",
    "\n",
    "print(f\"Customer Query: {customer_query_bad}\")\n",
    "print(f\"Agent Response: {agent_response_bad[:80]}...\")\n",
    "print(f\"\\n‚ùå Task Adherence Score: {result_poor_adherence.get('task_adherence', 'N/A')}\")\n",
    "print(f\"‚ùå Result: {result_poor_adherence.get('task_adherence_result', 'N/A')}\")\n",
    "print(f\"‚ö†Ô∏è  Agent violated instructions by processing a refund!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c071a325",
   "metadata": {},
   "source": [
    "## Step 8: Complex Agent Conversations\n",
    "\n",
    "Real agents often have complex multi-step conversations. Let's evaluate a realistic scenario with tool usage and extended interactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a706670b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üìä Complex Agent Scenario: Travel Planning Assistant\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d98d2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complex conversation with multiple tool calls\n",
    "complex_query = [\n",
    "    {\n",
    "        \"role\": \"system\", \n",
    "        \"content\": \"You are a travel planning assistant. You can help with weather information, flight searches, and hotel recommendations. Always provide helpful and accurate travel advice.\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\", \n",
    "        \"content\": \"I'm planning a trip to Tokyo next week. Can you help me with weather information and suggest what to pack?\"\n",
    "    }\n",
    "]\n",
    "\n",
    "complex_response = [\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": \"I'll help you plan your Tokyo trip! Let me check the weather forecast for next week.\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": [\n",
    "            {\n",
    "                \"type\": \"tool_call\",\n",
    "                \"tool_call_id\": \"call_tokyo_weather\",\n",
    "                \"name\": \"get_weather\",\n",
    "                \"arguments\": {\n",
    "                    \"location\": \"Tokyo, Japan\",\n",
    "                    \"units\": \"celsius\"\n",
    "                }\n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": \"Based on the weather forecast, Tokyo will have mild temperatures around 18-22¬∞C with some rain expected. I recommend packing: light layers for temperature changes, a waterproof jacket or umbrella for rain, comfortable walking shoes, and both casual and slightly formal clothing if you plan to visit restaurants or temples.\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# Evaluate intent resolution\n",
    "complex_intent_result = intent_evaluator(\n",
    "    query=complex_query,\n",
    "    response=complex_response\n",
    ")\n",
    "\n",
    "print(\"Intent Resolution:\")\n",
    "print(f\"  Score: {complex_intent_result.get('intent_resolution', 'N/A')}\")\n",
    "print(f\"  Result: {complex_intent_result.get('intent_resolution_result', 'N/A')}\")\n",
    "\n",
    "# Evaluate task adherence\n",
    "complex_task_result = task_adherence_evaluator(\n",
    "    query=complex_query,\n",
    "    response=complex_response\n",
    ")\n",
    "\n",
    "print(\"\\nTask Adherence:\")\n",
    "print(f\"  Score: {complex_task_result.get('task_adherence', 'N/A')}\")\n",
    "print(f\"  Result: {complex_task_result.get('task_adherence_result', 'N/A')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d2d0037",
   "metadata": {},
   "source": [
    "## Step 9: Batch Evaluation\n",
    "\n",
    "In real-world applications, you'll want to evaluate multiple agent interactions at once. Let's create a comprehensive batch evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e87bd280",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create multiple evaluation scenarios\n",
    "evaluation_scenarios = [\n",
    "    {\n",
    "        \"name\": \"Customer Support - Product Info\",\n",
    "        \"query\": \"What are the features of your premium subscription?\",\n",
    "        \"response\": \"Our premium subscription includes unlimited storage, priority support, advanced analytics, and collaboration tools for teams up to 50 members.\",\n",
    "        \"expected_intent\": \"product_information\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Customer Support - Billing Issue\", \n",
    "        \"query\": \"I was charged twice this month, can you help?\",\n",
    "        \"response\": \"I understand your concern about the duplicate charge. Let me look into your billing history and I'll make sure to resolve this for you right away.\",\n",
    "        \"expected_intent\": \"billing_support\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Travel Assistant - Weather Query\",\n",
    "        \"query\": \"What should I expect for weather in London this weekend?\",\n",
    "        \"response\": \"This weekend in London, expect cloudy skies with temperatures around 15-18¬∞C (59-64¬∞F). There's a 40% chance of light rain on Saturday, so I'd recommend bringing a light jacket and umbrella.\",\n",
    "        \"expected_intent\": \"weather_information\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Off-Topic Response\",\n",
    "        \"query\": \"What's the capital of France?\",\n",
    "        \"response\": \"I love cooking pasta! Here's my favorite recipe for spaghetti carbonara...\",\n",
    "        \"expected_intent\": \"geography_question\"\n",
    "    }\n",
    "]\n",
    "\n",
    "print(f\"‚úÖ Created {len(evaluation_scenarios)} evaluation scenarios\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b2d753a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run batch evaluation\n",
    "print(\"üìä BATCH AGENT EVALUATION RESULTS\\n\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "evaluation_results = []\n",
    "\n",
    "for i, scenario in enumerate(evaluation_scenarios, 1):\n",
    "    print(f\"\\nScenario {i}: {scenario['name']}\")\n",
    "    print(f\"Query: {scenario['query']}\")\n",
    "    \n",
    "    # Evaluate intent resolution\n",
    "    intent_result = intent_evaluator(\n",
    "        query=scenario['query'],\n",
    "        response=scenario['response']\n",
    "    )\n",
    "    \n",
    "    result_summary = {\n",
    "        'scenario': scenario['name'],\n",
    "        'intent_score': intent_result.get('intent_resolution', 0),\n",
    "        'intent_result': intent_result.get('intent_resolution_result', 'unknown')\n",
    "    }\n",
    "    \n",
    "    evaluation_results.append(result_summary)\n",
    "    \n",
    "    print(f\"Intent Score: {result_summary['intent_score']} ({result_summary['intent_result']})\")\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"SUMMARY STATISTICS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "intent_scores = [r['intent_score'] for r in evaluation_results if isinstance(r['intent_score'], (int, float))]\n",
    "passed_intent = len([r for r in evaluation_results if r['intent_result'] == 'pass'])\n",
    "\n",
    "print(f\"Average Intent Resolution Score: {sum(intent_scores)/len(intent_scores):.2f}\")\n",
    "print(f\"Intent Resolution Pass Rate: {passed_intent}/{len(evaluation_results)} ({passed_intent/len(evaluation_results)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d4461b",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "You've successfully learned how to evaluate AI agents using Azure AI Foundry's specialized evaluators! \n",
    "\n",
    "### What You Accomplished\n",
    "- Used **IntentResolutionEvaluator** to measure intent understanding\n",
    "- Assessed **ToolCallAccuracyEvaluator** for correct tool selection\n",
    "- Applied **TaskAdherenceEvaluator** to ensure agents stay within scope\n",
    "- Evaluated complex multi-step agent conversations\n",
    "- Created batch evaluation workflows for multiple scenarios\n",
    "\n",
    "### Key Takeaways\n",
    "- Agent evaluators provide specialized metrics for agentic workflows beyond simple query-response\n",
    "- Binary pass/fail results with detailed reasoning help identify specific improvement areas\n",
    "- Tool evaluation is crucial for agents that interact with external systems\n",
    "- Task adherence ensures agents maintain their intended purpose and boundaries\n",
    "- Combining quality and agent evaluators provides comprehensive assessment\n",
    "\n",
    "### Production Best Practices\n",
    "1. **Continuous Evaluation** - Set up automated evaluation pipelines for agent deployments\n",
    "2. **Threshold Monitoring** - Configure alerts when scores drop below acceptable levels\n",
    "3. **A/B Testing** - Compare different agent configurations using evaluation metrics\n",
    "4. **User Feedback Integration** - Combine automated evaluations with human feedback\n",
    "5. **Tool Coverage Testing** - Ensure all available tools are properly tested\n",
    "\n",
    "Great work! üéâ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
