#!/usr/bin/env python3
"""
Azure AI Search Index Setup Script

This script sets up an Azure AI Search index for the Zava product catalog, and enables 
semantic search capabilities through vector embeddings generated by Azure OpenAI.

Prerequisites:
- Azure AI Search Service configured
- Azure OpenAI Service with text-embedding-ada-002 model deployed
- Environment variables set in .env file or environment
- Azure CLI login (az login)

Usage:
    python setup_aisearch.py [--data-file DATA_FILE] [--max-products MAX_PRODUCTS]

Arguments:
    --data-file: Path to the CSV file containing product data (default: ../data/products-paints.csv)
    --max-products: Maximum number of products to process (default: 50, use 0 for all)
"""

import os
import sys
import argparse
import pandas as pd
from pathlib import Path
from typing import List, Dict
from azure.identity import DefaultAzureCredential, get_bearer_token_provider
from azure.search.documents import SearchClient
from azure.search.documents.indexes import SearchIndexClient
from azure.search.documents.indexes.models import (
    HnswParameters,
    HnswAlgorithmConfiguration,
    SemanticPrioritizedFields,
    SearchableField,
    SearchField,
    SearchFieldDataType,
    SearchIndex,
    SemanticSearch,
    SemanticConfiguration,
    SemanticField,
    SimpleField,
    VectorSearch,
    VectorSearchAlgorithmKind,
    VectorSearchAlgorithmMetric,
    ExhaustiveKnnAlgorithmConfiguration,
    ExhaustiveKnnParameters,
    VectorSearchProfile,
)
from openai import AzureOpenAI
from dotenv import load_dotenv


def load_environment():
    """Load environment variables from .env file and environment."""
    # Look for .env file in the repository root (two levels up from this script)
    env_path = Path(__file__).parent.parent.parent / ".env"
    if env_path.exists():
        print(f"Loading environment variables from {env_path}")
        load_dotenv(env_path)
    else:
        print("No .env file found in repository root, using system environment variables")
    
    # Verify required environment variables
    required_vars = ["AZURE_AISEARCH_ENDPOINT", "AZURE_OPENAI_ENDPOINT", "AZURE_AISEARCH_INDEX"]
    missing_vars = [var for var in required_vars if not os.getenv(var)]
    
    if missing_vars:
        print(f"ERROR: Missing required environment variables: {', '.join(missing_vars)}")
        print("Please set these variables in your .env file or environment.")
        sys.exit(1)


def delete_index(search_index_client: SearchIndexClient, search_index: str):
    """Delete existing search index if it exists."""
    try:
        search_index_client.get_index(search_index)
        print(f"Deleting existing index: {search_index}")
        search_index_client.delete_index(search_index)
        print(f"Successfully deleted index: {search_index}")
    except Exception:
        print(f"No existing index found: {search_index}")


def create_index_definition(name: str) -> SearchIndex:
    """
    Create Azure AI Search index definition for Zava products.
    
    Returns:
        SearchIndex with fields, semantic search, and vector search configurations
    """
    # Define the fields for the search index
    fields = [
        SimpleField(name="id", type=SearchFieldDataType.String, key=True),
        SearchableField(name="content", type=SearchFieldDataType.String),
        SimpleField(name="filepath", type=SearchFieldDataType.String),
        SearchableField(name="title", type=SearchFieldDataType.String),
        SimpleField(name="url", type=SearchFieldDataType.String),
        SimpleField(name="price", type=SearchFieldDataType.Double, filterable=True, sortable=True),
        SimpleField(name="stock", type=SearchFieldDataType.Int32, filterable=True, sortable=True),
        SearchField(
            name="contentVector",
            type=SearchFieldDataType.Collection(SearchFieldDataType.Single),
            searchable=True,
            # Size of the vector created by the text-embedding-ada-002 model
            vector_search_dimensions=1536,
            vector_search_profile_name="myHnswProfile",
        ),
    ]

    # Configure semantic search to prioritize content and titles
    semantic_config = SemanticConfiguration(
        name="default",
        prioritized_fields=SemanticPrioritizedFields(
            title_field=SemanticField(field_name="title"),
            keywords_fields=[],
            content_fields=[SemanticField(field_name="content")],
        ),
    )

    # Configure vector search algorithms
    vector_search = VectorSearch(
        algorithms=[
            HnswAlgorithmConfiguration(
                name="myHnsw",
                kind=VectorSearchAlgorithmKind.HNSW,
                parameters=HnswParameters(
                    m=4,
                    ef_construction=400,
                    ef_search=500,
                    metric=VectorSearchAlgorithmMetric.COSINE,
                ),
            ),
            ExhaustiveKnnAlgorithmConfiguration(
                name="myExhaustiveKnn",
                kind=VectorSearchAlgorithmKind.EXHAUSTIVE_KNN,
                parameters=ExhaustiveKnnParameters(
                    metric=VectorSearchAlgorithmMetric.COSINE
                ),
            ),
        ],
        profiles=[
            VectorSearchProfile(
                name="myHnswProfile",
                algorithm_configuration_name="myHnsw",
            ),
            VectorSearchProfile(
                name="myExhaustiveKnnProfile",
                algorithm_configuration_name="myExhaustiveKnn",
            ),
        ],
    )

    # Create semantic search configuration
    semantic_search = SemanticSearch(configurations=[semantic_config])

    # Create and return the search index
    index = SearchIndex(
        name=name,
        fields=fields,
        semantic_search=semantic_search,
        vector_search=vector_search,
    )

    return index


def gen_zava_products(path: str, n: int = None) -> List[Dict[str, any]]:
    """
    Process Zava product catalog and generate embeddings for each product.
    
    Args:
        path: Path to the products CSV file
        n: Number of products to process (if None or 0, process all products)
        
    Returns:
        List of product documents ready for indexing
    """
    openai_service_endpoint = os.environ["AZURE_OPENAI_ENDPOINT"]
    openai_deployment = "text-embedding-ada-002"

    # Initialize Azure OpenAI client with managed identity
    token_provider = get_bearer_token_provider(
        DefaultAzureCredential(), 
        "https://cognitiveservices.azure.com/.default"
    )
    client = AzureOpenAI(
        api_version="2025-02-01-preview",
        azure_endpoint=openai_service_endpoint,
        azure_deployment=openai_deployment,
        azure_ad_token_provider=token_provider
    )

    # Load product catalog
    print(f"Loading product data from: {path}")
    if not os.path.exists(path):
        raise FileNotFoundError(f"Product data file not found: {path}")
    
    products = pd.read_csv(path)
    
    # Limit to first n products if specified
    if n is not None and n > 0:
        products = products.head(n)
        print(f"Processing first {len(products)} products from catalog")
    else:
        print(f"Processing all {len(products)} products from catalog")
    
    items = []
    
    print("Generating embeddings for products...")
    for idx, product in enumerate(products.to_dict("records"), 1):
        print(f"Processing product {idx}/{len(products)}: {product['name']}")
        
        # Use description as the main content for embedding
        content = product["description"]
        # Use SKU as the unique identifier
        id = str(product["sku"])
        title = product["name"]
        # Create URL based on product name and SKU
        url = f"/products/{product['sku'].lower()}"
        
        # Generate embedding for the product description
        try:
            emb = client.embeddings.create(input=content, model=openai_deployment)
        except Exception as e:
            print(f"Error generating embedding for product {id}: {e}")
            continue
        
        # Create search document
        rec = {
            "id": id,
            "content": content,
            "filepath": f"{product['sku'].lower()}",
            "title": title,
            "url": url,
            "price": float(product["price"]),
            "stock": int(product["stock_level"]),
            "contentVector": emb.data[0].embedding,
        }
        items.append(rec)

    print(f"Successfully generated embeddings for {len(items)} products")
    return items


def main():
    """Main function to set up Azure AI Search index."""
    parser = argparse.ArgumentParser(
        description="Set up Azure AI Search index for Zava product catalog",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog=__doc__
    )
    parser.add_argument(
        "--data-file",
        default="../data/products-paints.csv",
        help="Path to the CSV file containing product data (default: ../data/products-paints.csv)"
    )
    parser.add_argument(
        "--max-products",
        type=int,
        default=50,
        help="Maximum number of products to process (default: 50, use 0 for all)"
    )
    
    args = parser.parse_args()
    
    print("üîç Azure AI Search Index Setup")
    print("=" * 50)
    
    # Load environment variables
    load_environment()
    
    # Resolve data file path relative to script location
    script_dir = Path(__file__).parent
    data_file_path = script_dir / args.data_file
    data_file_path = data_file_path.resolve()
    
    if not data_file_path.exists():
        print(f"ERROR: Data file not found: {data_file_path}")
        print("Please check the --data-file argument or ensure the file exists.")
        sys.exit(1)
    
    # Get configuration from environment variables
    search_endpoint = os.environ["AZURE_AISEARCH_ENDPOINT"]
    index_name = os.environ["AZURE_AISEARCH_INDEX"]
    
    print(f"Search endpoint: {search_endpoint}")
    print(f"Index name: {index_name}")
    print(f"Data file: {data_file_path}")
    print(f"Max products: {'All' if args.max_products == 0 else args.max_products}")
    print()
    
    try:
        # Initialize search index client
        print("Connecting to Azure AI Search service...")
        search_index_client = SearchIndexClient(
            search_endpoint, DefaultAzureCredential()
        )
        
        # Delete existing index if it exists
        delete_index(search_index_client, index_name)
        
        # Create new index with defined schema
        print(f"Creating search index: {index_name}")
        index = create_index_definition(index_name)
        search_index_client.create_or_update_index(index)
        print(f"Successfully created index: {index_name}")
        print()
        
        # Process product catalog and generate embeddings
        print("Processing product catalog and generating embeddings...")
        max_products = args.max_products if args.max_products > 0 else None
        docs = gen_zava_products(str(data_file_path), n=max_products)
        
        if not docs:
            print("ERROR: No product documents were generated")
            sys.exit(1)
        
        # Initialize search client for document upload
        print("Uploading products to search index...")
        search_client = SearchClient(
            endpoint=search_endpoint,
            index_name=index_name,
            credential=DefaultAzureCredential(),
        )
        
        # Upload all product documents to the index
        print(f"Uploading {len(docs)} products to index: {index_name}")
        result = search_client.upload_documents(docs)
        
        print()
        print("‚úÖ Setup completed successfully!")
        print(f"Uploaded {len(docs)} products to the search index")
        print("The Zava product catalog is now ready for semantic search.")
        
    except Exception as e:
        print(f"‚ùå Error during setup: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()